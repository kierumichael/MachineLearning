# MachineLearning
Child Online Safety Solutions Using Machine Learning.

The 21st Century.
Liquid Crystal Displays are the new windows to the souls. The driving force of information and the backbone of perception.
Thus we have decided to come up with a way to restore sanity on our online platforms.
We do this by coming up with a project that aims at securing the parts of the internet accessible and filtering out the gruesome and somewhat risky content.
Machine learning ,especially python's functional programming using numpy ,scikit-learn  e.t.c will be instrumental in developing the finished product aimed at child safety online.
changelog
-------------
Now that we have setup the  environment and tested the module with the iris dataset
we would like to create a new dataset that will be used to test the module against.
This dataset should have similar attributes to the iris dataset but be a set defining words ,and how to tell the meaning implied from the algorithm of choice.
the task is to:

1.Accomodate dynamicity in the set to create a list of words [we will start with 150 words as is in the iris set.]

2.Teach the model to identify obscene words from four distinct features.[similar to the iris features. i.e. petal length,petal width,sepal length sepal width to correspond to the four features to be researched further but eg. two real variables(string and string length) and two implied variables(sexual nature and sexual context).The fifth variable will be closely tied to the four and a variable age]

3.test the system against sample data through a split of the dataset. train the program to identify obscene words according to the rules set. vary age to filter out data accordingly.

How we do it
-------------
Content Risks: Exposure to harmful or age-inappropriate content, such as pornography, child sexual abuse material, hate speech and extremism, discriminatory or hateful content, disinformation, online games, gambling, content that endorses risky or unhealthy behaviours and violent content which may be upsetting or show criminal activity

we are building tools and models to make online content, social media and gaming platforms and other services safe for children? we do this through using frontier technologies to tackle inappropriate content.

-Using data science and AI to identify and analyse hateful content
-ML applications to advise and caution children about age-inappropriate content

The need for a safe environment for our children to grow.


added words.csv and words.py to show actual tests in the system


Added another file namely saferscreens-python-steps.mht which is a MHTML Document (.mht) .
This is an MHTML Document (.mht) to further elaborate the steps taken thus far with the test data stream Just download and open in a browser of your choice.
MHTML, an initialism of "MIME encapsulation of aggregate HTML documents", is a web page archive format used to combine, in a single computer file, the HTML code and its companion resources (such as images, Flash animations, Java applets, and audio and video files) that are represented by external hyperlinks in the web page's HTML code. 

